version: 2.1

parameters:
  aws_teardown:
    default: false
    type: boolean
  aws_teardown_branch:
    default: "n/a"
    type: string
  aws_teardown_sha:
    default: "n/a"
    type: string
  aws_teardown_datestring:
    default: "n/a"
    type: string

jobs:
  build_and_test:
    machine:
      enabled: true
      docker_layer_caching: true
    environment:
      - PARALLELISM: 4 # Input to influxdb/build.py
    parallelism: 4 # How many CircleCI test containers
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - checkout
      - run:
          name: Ensure CircleCI parallelism matches "./test.sh count"
          command: "[ `./test.sh count` -eq $CIRCLE_NODE_TOTAL ]"
      - run:
          name: Execute test
          command: ./test.sh ${CIRCLE_NODE_INDEX}
          no_output_timeout: 1500s
      - run:
          name: Rename packages
          command: |
            set -x
            if [ 0 -eq ${CIRCLE_NODE_INDEX} ]; then
              ls build
              mv build packages
            else
              mkdir -p packages
              touch packages/${CIRCLE_NODE_INDEX}-dummy.deb  # this is a hack to make persisting to workspace work for all parallel executors, even though some don't produce build output
            fi
      - store_artifacts:
          path: packages/
      - persist_to_workspace:
          root: .
          paths:
            - packages/*.deb
  # Note: command-level insertion of AWS environment variables is required to
  # shadow separate legacy credentials used for dl.influxdata.com s3 bucket in
  # other CI for this repo
  # see the following known issue for more info: https://support.circleci.com/hc/en-us/articles/360021415793-Wrong-AWS-credentials-being-used
  perf_test:
    machine:
      enabled: true
      docker_layer_caching: true
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - checkout
      - add_ssh_keys:
          fingerprints:
            - "91:0a:5b:a7:f9:46:77:f3:5d:4a:cf:d2:44:c8:2c:5a"
      - run:
          name: Run test in AWS instance
          no_output_timeout: 20m
          command: |
            set -x

            # get latest ubuntu 20.04 ami for us-west-2
            ami_id=$(AWS_ACCESS_KEY_ID=${TEST_AWS_ACCESS_KEY_ID} AWS_SECRET_ACCESS_KEY=${TEST_AWS_SECRET_ACCESS_KEY} aws --region us-west-2 ssm get-parameters --names /aws/service/canonical/ubuntu/server/20.04/stable/current/amd64/hvm/ebs-gp2/ami-id --query 'Parameters[0].[Value]' --output text)

            # launch ec2 instance
            instance_type="m5.large"
            datestring=$(date +%Y%m%d)
            instance_info=$(AWS_ACCESS_KEY_ID=${TEST_AWS_ACCESS_KEY_ID} AWS_SECRET_ACCESS_KEY=${TEST_AWS_SECRET_ACCESS_KEY} aws --region us-west-2 ec2 run-instances \
              --image-id $ami_id \
              --instance-type $instance_type \
              --block-device-mappings DeviceName=/dev/sda1,Ebs={VolumeSize=100} \
              --key-name circleci-oss-test \
              --security-group-ids sg-03004366a38eccc97 \
              --subnet-id subnet-0c079d746f27ede5e \
              --tag-specifications "ResourceType=instance,Tags=[{Key=Name,Value=oss-perftest-$datestring-${CIRCLE_BRANCH}-${CIRCLE_SHA1}}]")

            # get instance info
            ec2_instance_id=$(echo $instance_info | jq -r .Instances[].InstanceId)
            sleep 60

            ec2_ip=$(AWS_ACCESS_KEY_ID=${TEST_AWS_ACCESS_KEY_ID} AWS_SECRET_ACCESS_KEY=${TEST_AWS_SECRET_ACCESS_KEY} aws \
              --region us-west-2 \
              ec2 describe-instances \
                --instance-ids $ec2_instance_id \
                --query "Reservations[].Instances[].PublicIpAddress" \
                --output text)

            while [ -z $ec2_ip ]; do
              sleep 5
              ec2_ip=$(AWS_ACCESS_KEY_ID=${TEST_AWS_ACCESS_KEY_ID} AWS_SECRET_ACCESS_KEY=${TEST_AWS_SECRET_ACCESS_KEY} aws \
                --region us-west-2 \
                ec2 describe-instances \
                  --instance-ids $ec2_instance_id \
                  --query "Reservations[].Instances[].PublicIpAddress" \
                  --output text)
            done

            # push binary and script to instance
            debname=$(find /tmp/workspace/packages/influxdb*amd64.deb)
            base_debname=$(basename $debname)

            scp $debname ubuntu@$ec2_ip:/home/ubuntu/$base_debname
            scp run_perftest.sh ubuntu@$ec2_ip:/home/ubuntu/run_perftest.sh

            # run scripts
            ssh ubuntu@$ec2_ip \<< EOF
            sudo DEBIAN_FRONTEND=noninteractive apt-get install --assume-yes /home/ubuntu/$base_debname
            sudo systemctl unmask influxdb.service
            sudo systemctl start influxdb
            EOF

            ssh ubuntu@$ec2_ip \<< EOF
            nohup sudo CIRCLE_TEARDOWN=true CIRCLE_TOKEN=${CIRCLE_API_CALLBACK_TOKEN}  CLOUD2_BUCKET=${CLOUD2_PERFTEST_BUCKET} CLOUD2_ORG=${CLOUD2_PERFTEST_ORG} DATA_I_TYPE=m5.large DB_TOKEN=${CLOUD2_PERFTEST_TOKEN} INFLUXDB_VERSION=${CIRCLE_BRANCH} NGINX_HOST=localhost TEST_COMMIT=${CIRCLE_SHA1} CIRCLE_TEARDOWN_DATESTRING=$datestring ./run_perftest.sh > /home/ubuntu/perftest_log.txt 2>&1 &
            EOF
  aws_destroy_by_date:
    machine:
      enabled: true
      docker_layer_caching: true
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - checkout
      - add_ssh_keys:
          fingerprints:
            - "91:0a:5b:a7:f9:46:77:f3:5d:4a:cf:d2:44:c8:2c:5a"
      - run:
          name: Destroy AWS instances with datestring more than a day old
          no_output_timeout: 20m
          command: |
            set -x
            yesterday_date=$(date --date"yesterday" +%Y%md)
            today=$(date +%Y%m%d)
            instance_info=$(AWS_ACCESS_KEY_ID=${TEST_AWS_ACCESS_KEY_ID} AWS_SECRET_ACCESS_KEY=${TEST_AWS_SECRET_ACCESS_KEY} aws --region us-west-2 ec2 describe-instances --filters "Name=tag:Name,Values=oss-perftest-*" --query "Reservations[].Instances[].[InstanceId, Tags[?Key==`Name`]]" --output text)
            for info in $instance_info; do
              name=$(echo $info | cut -d ' ' -f2)
              date=$(echo $name | cut -d '-' -f3)
              if [ $(expr $today - $yesterday_date) -gt 1 ]; then
                instance_id=$(echo $info | cut -d ' ' -f1)
                AWS_ACCESS_KEY_ID=${TEST_AWS_ACCESS_KEY_ID} AWS_SECRET_ACCESS_KEY=${TEST_AWS_SECRET_ACCESS_KEY} aws --region us-west-2 ec2 terminate-instances --instance-ids $instance_id
              fi
            done
  aws_destroy_by_name:
    machine:
      enabled: true
      docker_layer_caching: true
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - checkout
      - add_ssh_keys:
          fingerprints:
            - "91:0a:5b:a7:f9:46:77:f3:5d:4a:cf:d2:44:c8:2c:5a"
      - run:
          name: Destroy AWS instances by constructing name from arguments
          no_output_timeout: 20m
          command: |
            set -x
            name=oss-perftest-<< pipeline.parameters.aws_teardown_datestring >>-<< pipeline.parameters.aws_teardown_branch >>-<< pipeline.parameters.aws_teardown_sha >>
            instance_id=$(AWS_ACCESS_KEY_ID=${TEST_AWS_ACCESS_KEY_ID} AWS_SECRET_ACCESS_KEY=${TEST_AWS_SECRET_ACCESS_KEY} aws --region us-west-2 ec2 describe-instances --filters "Name=tag:Name,Values=$name" --query 'Reservations[].Instances[].InstanceId' --output text)
            AWS_ACCESS_KEY_ID=${TEST_AWS_ACCESS_KEY_ID} AWS_SECRET_ACCESS_KEY=${TEST_AWS_SECRET_ACCESS_KEY} aws --region us-west-2 ec2 terminate-instances --instance-ids $instance_id

workflows:
  version: 2
  on_push:
    when:
      not: << pipeline.parameters.aws_teardown >>
    jobs:
      - build_and_test
      - perf_test:
          requires:
            - build_and_test
          filters:
            branches:
              only:
                - "1.8"
                - "perftests-1.8"
  aws_destroy_daily:
    triggers:
      - schedule:
          # run every day at 10pm -- note: use spaces, not tabs
          cron: "0 22 * * *"
          filters:
            branches:
              only:
                - "1.8"
                - master
    jobs:
      - aws_destroy_by_date
  aws_destroy_callback:
    when: << pipeline.parameters.aws_teardown >>
    jobs:
      - aws_destroy_by_name
