Notes for two phase query refactor
-----------------------------------------------------------------------

// when done, the nextTime on QueryMapResult will be nil
datastore.Query(databaseQuery *DatabaseQuery, yield func(result *QueryMapResult) err) err
  q := databaseQuery.Query
  mr := NewQueryMapResult(q)

  // iterate through points
  shouldYieldMr := q.YieldPoint(point, mr)
  if shouldYieldMr {
    yield(mr)
    mr = NewQueryMapResult(q)
  }

// if a query has a join, we run a stupid reduce that just returns all points
// the engine will then reconstruct those and run a local map reduce

// for percentile queries, it can just serialize the raw values array as long as
// they're all in the same group by period. Shahid says to just serialize the percentile
// aggregator state.

type DatabaseQuery struct {
  user string
  database string
  query *SelectQuery
}

// queries can have multiple mappers. like in the case that you're doing two aggregations: select count(val), sum(val) from foo
// each mapper will emit a query map result. because of this the query map result needs to return which reducer should be
// used to process the map result.

QueryMapResult
  data []byte
  reducer (some enum)
  startTime
  endTime
  nextTime

# authenticating the user happens before here
engine.Query(databaseQuery *DatabaseQuery, yeild func(series *protocol.Series) err) err
  mrJob := NewMapReduceJob(databaseQuery.Query, yield)

  f := func(result *QueryMapResult) err {
    return mrJob.Reduce(result)
  }
  retunr self.coordinator.DistributeQuery(databaseQuery, f)
}

type Reducer interface {
  Decode([]byte) err
  Reduce(queryMapResult *QueryMapResult) err
  GetValues(seriesName *string, group Group) []*protocol.FieldValue
}

type MapReduceJob struct {
  reducers []Reducer
}

func NewMapReduceJob(query *protocol.Query, yeild func(series *protocol.Series) err) *MapReduceJob {
  mr := &MapReduceJob{query: query}
}

func (self *MapReduceJob) Reduce(result *QueryMapResult) err {
}

coordinator.DistributeQuery(databaseQuery *DatabaseQuery, yield func(result *QueryMapResult) err)



select * from response_time as r1 inner join response_time as r2 where r1.host = 'hosta' and r2.host = 'hostb'
select * form foo limit 10

query := "select count(uid), distinct(uid) from foo group by time(1d)"
myChan := make(chan *QueryMapResult)
datastore.Query(query, myChan)

OLD STUFF
sendBatch does a weird thing where it returns the number of points dropped so that number can be readded to the limit.
This is odd. Instead, we should decrement the limit for a given series name when we yield the points (or in the new case, the
query map result)

select count(foo) from bar group by time(5m), org_id


New Notes on Implementation:

thing that yields points to the mapper:
  will have to do the grouping for it. So the mapper won't worry about grouping at all.
  will have to ensure that the size of those things going to get grouped don't go over the total serialization limit
  will call out to mapper to process the points and get results back. will buffer the results based on group. then will yield when the group is done or the size limit is hit.

the thing that yields to the reducer:
  will get a map result with the reducer to call and the group (bytes?)
  will call out to the reducer that won't have to worry about groupings.
  the reducer will return a series object
  the thing will yield series objects to the yield function

coord creates ReducePhase
coord gathers MapResults, yields to ReducePhase


datastore yields series name and points into the MapJob as they are ready
  does auth check to make sure user can see series (or if regex, each one)
  does any point filters, yields points to MapJob.
MapJob yields to all mappers associated with the query
Mappers when yielded points optionally return MapResults to MapJob
MapJob buffers MapResults and sends to MapResultStream out when appropriate (size, whatever)
ReduceJob gets ShuffleAndReduce called with MapResults
  shuffles together, yields to individual reducers
Reducers optionally yield points which then get sent to the QueryResultStream