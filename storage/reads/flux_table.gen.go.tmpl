package reads

import (
    "errors"
	"fmt"
	"math"
	"sync"

	"github.com/apache/arrow/go/arrow/array"
	"github.com/influxdata/flux"
	"github.com/influxdata/flux/arrow"
	"github.com/influxdata/flux/execute"
    "github.com/influxdata/flux/interval"
	"github.com/influxdata/flux/memory"
	"github.com/influxdata/flux/values"
	"github.com/influxdata/influxdb/models"
	"github.com/influxdata/influxdb/storage/reads/datatypes"
	"github.com/influxdata/influxdb/tsdb/cursors"
)
{{range .}}
//
// *********** {{.Name}} ***********
//

type {{.name}}Table struct {
	table
	mu     sync.Mutex
	cur    cursors.{{.Name}}ArrayCursor
	alloc  *memory.Allocator
}

func new{{.Name}}Table(
	done chan struct{},
	cur cursors.{{.Name}}ArrayCursor,
	bounds execute.Bounds,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *{{.name}}Table {
	t := &{{.name}}Table{
		table: newTable(done, bounds, key, cols, defs, cache, alloc),
		cur:   cur,
	}
	t.readTags(tags)
	t.init(t.advance)

	return t
}

func (t *{{.name}}Table) Close() {
	t.mu.Lock()
	if t.cur != nil {
		t.cur.Close()
		t.cur = nil
	}
	t.mu.Unlock()
}

func (t *{{.name}}Table) Statistics() cursors.CursorStats {
	t.mu.Lock()
	defer t.mu.Unlock()
	cur := t.cur
	if cur == nil {
		return cursors.CursorStats{}
	}
	cs := cur.Stats()
	return cursors.CursorStats{
		ScannedValues: cs.ScannedValues,
		ScannedBytes:  cs.ScannedBytes,
	}
}

func (t *{{.name}}Table) Do(f func(flux.ColReader) error) error {
	return t.do(f, t.advance)
}

func (t *{{.name}}Table) advance() bool {
	a := t.cur.Next()
	l := a.Len()
	if l == 0 {
		return false
	}

	// Retrieve the buffer for the data to avoid allocating
	// additional slices. If the buffer is still being used
	// because the references were retained, then we will
	// allocate a new buffer.
	cr := t.allocateBuffer(l)
	cr.cols[timeColIdx] = arrow.NewInt(a.Timestamps, t.alloc)
	cr.cols[valueColIdx] = t.toArrowBuffer(a.Values)
	t.appendTags(cr)
	t.appendBounds(cr)
	return true
}

// group table

type {{.name}}GroupTable struct {
	table
	mu     sync.Mutex
	gc     GroupCursor
	cur    cursors.{{.Name}}ArrayCursor
}

func new{{.Name}}GroupTable(
	done chan struct{},
	gc GroupCursor,
	cur cursors.{{.Name}}ArrayCursor,
	bounds execute.Bounds,
	key flux.GroupKey,
	cols []flux.ColMeta,
	tags models.Tags,
	defs [][]byte,
	cache *tagsCache,
	alloc *memory.Allocator,
) *{{.name}}GroupTable {
	t := &{{.name}}GroupTable{
		table: newTable(done, bounds, key, cols, defs, cache, alloc),
		gc:    gc,
		cur:   cur,
	}
	t.readTags(tags)
	t.init(t.advance)

	return t
}

func (t *{{.name}}GroupTable) Close() {
	t.mu.Lock()
	if t.cur != nil {
		t.cur.Close()
		t.cur = nil
	}
	if t.gc != nil {
		t.gc.Close()
		t.gc = nil
	}
	t.mu.Unlock()
}

func (t *{{.name}}GroupTable) Do(f func(flux.ColReader) error) error {
	return t.do(f, t.advance)
}

func (t *{{.name}}GroupTable) advance() bool {
	if t.cur == nil {
		// For group aggregates, we will try to get all the series and all table buffers within those series
		// all at once and merge them into one row when this advance() function is first called.
		// At the end of this process, t.advanceCursor() already returns false and t.cur becomes nil.
		// But we still need to return true to indicate that there is data to be returned.
		// The second time when we call this advance(), t.cur is already nil, so we directly return false.
		return false
	}
	var arr *cursors.{{.Name}}Array
	var len int
	for {
		arr = t.cur.Next()
		len = arr.Len()
		if len > 0 {
			break
		}
		if !t.advanceCursor() {
			return false
		}
	}

	// handle the group without aggregate case
	if t.gc.Aggregate() == nil {
		// Retrieve the buffer for the data to avoid allocating
		// additional slices. If the buffer is still being used
		// because the references were retained, then we will
		// allocate a new buffer.
		colReader := t.allocateBuffer(len)
		colReader.cols[timeColIdx] = arrow.NewInt(arr.Timestamps, t.alloc)
		colReader.cols[valueColIdx] = t.toArrowBuffer(arr.Values)
		t.appendTags(colReader)
		t.appendBounds(colReader)
		return true
	}

	aggregate, err := determine{{.Name}}AggregateMethod(t.gc.Aggregate().Type)
	if err != nil {
		t.err = err
		return false
	}

	ts, v := aggregate(arr.Timestamps, arr.Values)
	timestamps, values := []int64{ts}, []{{.Type}}{v}
	for {
		arr = t.cur.Next()
		if arr.Len() > 0 {
			ts, v := aggregate(arr.Timestamps, arr.Values)
			timestamps = append(timestamps, ts)
			values = append(values, v)
			continue
		}

		if !t.advanceCursor() {
			break
		}
	}
	timestamp, value := aggregate(timestamps, values)

	colReader := t.allocateBuffer(1)
	if IsSelector(t.gc.Aggregate()) {
		colReader.cols[timeColIdx] = arrow.NewInt([]int64{timestamp}, t.alloc)
		colReader.cols[valueColIdx] = t.toArrowBuffer([]{{.Type}}{value})
	} else {
		colReader.cols[valueColIdxWithoutTime] = t.toArrowBuffer([]{{.Type}}{value})
	}
	t.appendTags(colReader)
	t.appendBounds(colReader)
	return true
}

type {{.name}}AggregateMethod func([]int64, []{{.Type}}) (int64, {{.Type}})

// determine{{.Name}}AggregateMethod returns the method for aggregating
// returned points within the same group. The incoming points are the
// ones returned for each series and the method returned here will
// aggregate the aggregates.
func determine{{.Name}}AggregateMethod(agg datatypes.Aggregate_AggregateType) ({{.name}}AggregateMethod, error){
 	switch agg {
	case datatypes.AggregateTypeFirst:
		return aggregateFirstGroups{{.Name}}, nil
	case datatypes.AggregateTypeLast:
		return aggregateLastGroups{{.Name}}, nil
	case datatypes.AggregateTypeCount:
		{{if eq .Name "Integer"}}
		return aggregateCountGroups{{.Name}}, nil
		{{else}}
		return nil, errors.New("unsupported for aggregate count: {{.Name}}")
		{{end}}
	case datatypes.AggregateTypeSum:
		{{if and (ne .Name "Boolean") (ne .Name "String")}}
		return aggregateSumGroups{{.Name}}, nil
		{{else}}
		return nil, errors.New("unsupported for aggregate sum: {{.Name}}")
		{{end}}
	case datatypes.AggregateTypeMin:
		{{if and (ne .Name "Boolean") (ne .Name "String")}}
		return aggregateMinGroups{{.Name}}, nil
		{{else}}
		return nil, errors.New("unsupported for aggregate min: {{.Name}}")
		{{end}}
	case datatypes.AggregateTypeMax:
		{{if and (ne .Name "Boolean") (ne .Name "String")}}
		return aggregateMaxGroups{{.Name}}, nil
		{{else}}
		return nil, errors.New("unsupported for aggregate max: {{.Name}}")
		{{end}}
	default:
		return nil, fmt.Errorf("unknown/unimplemented aggregate type: %v", agg)
	}
}

{{if and (ne .Name "Boolean") (ne .Name "String")}}
func aggregateMinGroups{{.Name}}(timestamps []int64, values []{{.Type}}) (int64, {{.Type}}) {
	value := values[0]
	timestamp := timestamps[0]

	for i := 1; i < len(values); i++ {
		if value > values[i] {
			value = values[i]
			timestamp = timestamps[i]
		}
	}

	return timestamp, value
}
{{end}}

{{if and (ne .Name "Boolean") (ne .Name "String")}}
func aggregateMaxGroups{{.Name}}(timestamps []int64, values []{{.Type}}) (int64, {{.Type}}) {
	value := values[0]
	timestamp := timestamps[0]

	for i := 1; i < len(values); i++ {
		if value < values[i] {
			value = values[i]
			timestamp = timestamps[i]
		}
	}

	return timestamp, value
}
{{end}}

// For group count and sum, the timestamp here is always math.MaxInt64.
// their final result does not contain _time, so this timestamp value can be anything
// and it won't matter.
{{if eq .Name "Integer"}}
func aggregateCountGroups{{.Name}}(timestamps []int64, values []{{.Type}}) (int64, {{.Type}}) {
	return aggregateSumGroups{{.Name}}(timestamps, values)
}
{{end}}

{{if and (ne .Name "Boolean") (ne .Name "String")}}
func aggregateSumGroups{{.Name}}(_ []int64, values []{{.Type}}) (int64, {{.Type}}) {
	var sum {{.Type}}
	for _, v := range values {
		sum += v
	}
	return math.MaxInt64, sum
}
{{end}}

func aggregateFirstGroups{{.Name}}(timestamps []int64, values []{{.Type}}) (int64, {{.Type}}) {
	value := values[0]
	timestamp := timestamps[0]

	for i := 1; i < len(values); i++ {
		if timestamp > timestamps[i] {
			value = values[i]
			timestamp = timestamps[i]
		}
	}

	return timestamp, value
}

func aggregateLastGroups{{.Name}}(timestamps []int64, values []{{.Type}}) (int64, {{.Type}}) {
	value := values[0]
	timestamp := timestamps[0]

	for i := 1; i < len(values); i++ {
		if timestamp < timestamps[i] {
			value = values[i]
			timestamp = timestamps[i]
		}
	}

	return timestamp, value
}

func (t *{{.name}}GroupTable) advanceCursor() bool {
	t.cur.Close()
	t.cur = nil
	for t.gc.Next() {
		cur := t.gc.Cursor()
		if cur == nil {
			continue
		}

		if typedCur, ok := cur.(cursors.{{.Name}}ArrayCursor); !ok {
			// TODO(sgc): error or skip?
			cur.Close()
			t.err = &GroupCursorError {
                typ: "{{.name}}",
                cursor: cur,
			}
			return false
		} else {
			t.readTags(t.gc.Tags())
			t.cur = typedCur
			return true
		}
	}
	return false
}

func (t *{{.name}}GroupTable) Statistics() cursors.CursorStats {
	if t.cur == nil {
		return cursors.CursorStats{}
	}
	cs := t.cur.Stats()
	return cursors.CursorStats{
		ScannedValues: cs.ScannedValues,
		ScannedBytes:  cs.ScannedBytes,
	}
}

{{end}}
